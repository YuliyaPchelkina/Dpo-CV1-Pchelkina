{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baf8ea35",
   "metadata": {},
   "source": [
    "## Лабораторная работа 3. Работа с веб-камерой\n",
    "\n",
    "### Цель: Отработать навыки работы с веб-камерой с использованием OpenCV.\n",
    "\n",
    "Задачи\n",
    "1. Считать видеопоток с веб-камеры, реализовать отображение видеопотока в блокноте.\n",
    "2. Детектировать лица на кадрах видеопотока с использованием метода cv2.CascadeClassifier.\n",
    "3. Экстрактировать признаки из изображения детектированного лица.\n",
    "4. Создать набор данных (признаков) своего лица.\n",
    "5. Реализовать метод сравнения признаков лица, детектируемого в потоке, с набором признаков из п.4. В случае нахождения \"похожего\" лица в наборе данных признать лицо в видеопотоке идентифицированным (eg. \"Павел Якимов\"), иначе: \"Unknown person\".\n",
    "6. Вывести результат идентификации на экран"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75dd06be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from IPython.display import display, Image, clear_output\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "#from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8dbd4",
   "metadata": {},
   "source": [
    "### Считываем видеопоток с веб-камеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "130f1c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Released Video Resource\n"
     ]
    }
   ],
   "source": [
    "# параметр cv2.CAP_DSHOW исправляет \"перевернутое изображение\"\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "               \n",
    "        if not ret:\n",
    "            cap.release()\n",
    "            print('Released Video Resource') \n",
    "            break\n",
    "        \n",
    "        if cv2.waitKey(10) == 27: # Клавиша Esc\n",
    "            break\n",
    "        \n",
    "        \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        #убрали оси\n",
    "        axis('off')\n",
    "        # название вывели\n",
    "        title('Input Stream')\n",
    "        # выводим на экран\n",
    "        imshow(frame)\n",
    "        show()\n",
    "        clear_output(wait = True)\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    cap.release()\n",
    "    print('Released Video Resource')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45634178",
   "metadata": {},
   "source": [
    "### Определение лица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67bf80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_face(image):\n",
    "    \n",
    "    #face_cascade = cv2.CascadeClassifier(haarcascade_frontalface_default.xml\")\n",
    "    \n",
    "    # не cчитал загруженный каскад, но сработал такой вот фрагмент кода:\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    \n",
    "        \n",
    "    # конвертируем в оттенки серого\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # faces = face_cascade.detectMultiScale(gray, scaleFactor, minNeighbors, minSize)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.2, 15)\n",
    "    \n",
    "    # рисуем прямоугольник вокруг лица\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "    #print('Faces found: ', len(faces))\n",
    "    return image   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f14127c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "display_handle=display(None, display_id=True)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            video.release()\n",
    "            print (\"Released Video Resource\")\n",
    "            break\n",
    "        \n",
    "        frame = find_face(frame)\n",
    "        _, frame = cv2.imencode('.jpeg', frame)\n",
    "        display_handle.update(Image(data=frame.tobytes()))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "finally:\n",
    "    video.release()\n",
    "    display_handle.update(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c53ce0c",
   "metadata": {},
   "source": [
    "### Сбор данных, создание набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fadf135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir data_face\n",
    "# mkdir data_eyes\n",
    "# mkdir data_smile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4320cedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Введите имя  ==>  Julia\n",
      "\n",
      " Пожалуйста, смотрите в камеру\n",
      "\n",
      " Набор данных для пользователя Julia создан\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "cam.set(3, 640) # set video width\n",
    "cam.set(4, 480) # set video height\n",
    "\n",
    "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "eye_detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_eye.xml\")\n",
    "smile_detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_smile.xml\")\n",
    "\n",
    "# указать имя пользователя, которое буде в названии файлов\n",
    "face_id = input('\\n Введите имя  ==>  ')\n",
    "\n",
    "print(\"\\n Пожалуйста, смотрите в камеру\")\n",
    "\n",
    "\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "count3 = 0\n",
    "\n",
    "while(True):\n",
    "    ret, img = cam.read()\n",
    "    #img = cv2.flip(img, -1) # flip video image vertically\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray, 1.3, 5)\n",
    "    eyes = eye_detector.detectMultiScale(gray, 1.3, 5)\n",
    "    smiles = smile_detector.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)     \n",
    "        count1 += 1\n",
    "        # сохраняем изображения в папку \n",
    "        cv2.imwrite(\"data_face/\" + str(face_id) + '.' + str(count1) + \".jpg\", gray[y:y+h,x:x+w])\n",
    "        cv2.imshow('image', img)\n",
    "\n",
    "        \n",
    "    for (x,y,w,h) in eyes:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)     \n",
    "        count2 += 1\n",
    "        cv2.imwrite(\"data_eyes/\" + str(face_id) + '.' + str(count2) + \".jpg\", gray[y:y+h,x:x+w])\n",
    "        cv2.imshow('image', img)    \n",
    "        \n",
    "        \n",
    "#    for (x,y,w,h) in smiles:\n",
    "#        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)     \n",
    "#        count3 += 1\n",
    "#        cv2.imwrite(\"data_smile/\" + str(face_id) + '.' + str(count3) + \".jpg\", gray[y:y+h,x:x+w])\n",
    "#        cv2.imshow('image', img)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # 'ESC' чтобы остановить видео\n",
    "    k = cv2.waitKey(100) & 0xff \n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "    # Делаем 50 фоток\n",
    "    elif count1 >= 50: \n",
    "         break\n",
    "\n",
    "print(\"\\n Набор данных для пользователя\", face_id, \"создан\")\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ff75b",
   "metadata": {},
   "source": [
    "#### обучаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78cbaccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e27e15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  будет принимать все фотографии по указанному пути, возвращая 2 массива: «Идентификаторы(lds)» и «Лица(Faces)»\n",
    "from PIL import Image\n",
    "def getImg(path):\n",
    "    imagePaths = [os.path.join(path,f) for f in os.listdir(path)] \n",
    "    #print(imagePaths)\n",
    "    faceSamples=[]\n",
    "    ids = []\n",
    "    \n",
    "    for imagePath in imagePaths:\n",
    "        PIL_img = Image.open(imagePath).convert('L') # convert it to grayscale\n",
    "        img_numpy = np.array(PIL_img,'uint8')\n",
    "        id = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "        faces = detector.detectMultiScale(img_numpy)\n",
    "        \n",
    "        for (x,y,w,h) in faces:\n",
    "            faceSamples.append(img_numpy[y:y+h,x:x+w])\n",
    "            ids.append(id)\n",
    "    \n",
    "    return faceSamples,ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "417fab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# путь к файлам\n",
    "#path_ = \"data_face\"\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# обучаем\n",
    "faces, ids = getImg(\"data_face\")\n",
    "recognizer.train(faces, np.array(ids))\n",
    "# сохраняем результат обучения в файл\n",
    "recognizer.write('train/trainer_face.yml') \n",
    "\n",
    "\n",
    "#recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "#detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_eye.xml\")\n",
    "#faces, ids = getImg(\"data_eyes\")\n",
    "#recognizer.train(faces, np.array(ids))\n",
    "#recognizer.write('train/trainer_eyes.yml')\n",
    "\n",
    "\n",
    "#recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "#detector = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_smile.xml\")\n",
    "#faces, ids = getImg(\"data_smile\")\n",
    "#recognizer.train(faces, np.array(ids))\n",
    "#recognizer.write('train/trainer_smile.yml')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa2b6d",
   "metadata": {},
   "source": [
    "#### Распознаем\n",
    "\n",
    "\n",
    "только по лицу (но можно также и по другим признакам)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52aacb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer_face = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer_face.read('train/trainer_face.yml')\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "#recognizer_eye = cv2.face.LBPHFaceRecognizer_create()\n",
    "#recognizer_eye.read('train/trainer_eyes.yml')\n",
    "#eyeCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b24ac02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Released Video Resource\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "cam.set(3, 640) # set video widht\n",
    "cam.set(4, 480) # set video height\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, img = cam.read()\n",
    "               \n",
    "        if not ret:\n",
    "            cam.release()\n",
    "            print('Released Video Resource') \n",
    "            break\n",
    "        \n",
    "        if cv2.waitKey(10) == 27: # Клавиша Esc\n",
    "            break\n",
    "        \n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        faces = faceCascade.detectMultiScale(gray, 1.2, 5)\n",
    "        \n",
    "        for(x,y,w,h) in faces:\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "            id, confidence = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "\n",
    "            if (confidence < 70):\n",
    "                \n",
    "                id = \"Julia\"\n",
    "                 \n",
    "                confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "            else:\n",
    "                id = \"unknown\"\n",
    "                confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        \n",
    "        cv2.putText(img, str(id), (x+5,y-5), font, 1, (255,255,255), 2)\n",
    "        \n",
    "        # вероятность в процентах\n",
    "        cv2.putText(img, str(confidence), (x+5,y+h-5), font, 1, (255,255,0), 1)\n",
    "        \n",
    "              \n",
    "        \n",
    "        #убрали оси\n",
    "        axis('off')\n",
    "        \n",
    "        # выводим на экран\n",
    "        imshow(img)\n",
    "        show()\n",
    "        clear_output(wait = True)\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    cam.release()\n",
    "    print('Released Video Resource')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842228ab",
   "metadata": {},
   "source": [
    "Результат, конечно, будет зависеть от:\n",
    "- объема набора данных (у меня 50 снимков)\n",
    "- точности (у меня это confidence < 70)\n",
    "- от количества признаков (глаза, улыбка и т.д.). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b70990f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
